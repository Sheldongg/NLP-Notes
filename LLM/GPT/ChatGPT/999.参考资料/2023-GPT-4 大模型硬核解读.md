> [原文地址](https://mp.weixin.qq.com/s/2CebXxwZvm7sRgHih2sC2g)

# GPT-4 大模型硬核解读

之前我们一直说自然语言处理是人工智能王冠上最大的那颗珍珠，但如今用世俗的珍珠或者王冠形容已经不合适了。多模态大模型带给人类世界的震撼，就如人工智能企业 Hugging Face（因提供开源预训练模型库而闻名）的联合创始人 Thomas Wolf 所述：“在过去的几年里，好的多模态模型一直是许多大型技术实验室的圣杯。“其中多模态指的是融合文本、图像、视频或音频等多种模态作为输入或输出。

作为“圣杯”的代表之一，GPT-4 这个标签代表第 4 代生成式预训练变换模型(Generative Pre-trained Transformer 4)，是 OpenAI 在 2023 年 3 月 14 日公开的一种多模态模型，是对前几个月发布的 ChatGPT 的多模态升级。GPT-4 模型可对图文多模态输入生成应答文字，以及对视觉元素的分类、分析和隐含语义提取，并表现出优秀的应答能力。业内文章大多从侧面宣传 GPT-4 的优秀，却很少触及其核心技术内核。

![OpenAI 的相关信息](https://assets.ng-tech.icu/item/20230404112552.png)

本文将通过 OpenAI 和其他 AI 巨头已发表的大语言模型或多模态论文来详细阐述和分析与 GPT-4 相关核心技术要点、技术架构、训练流程、算力、局限与产业未来，告诉大家为何我们的下一代会从“内卷”过渡到“人机互卷”。

# GPT-4 核心技术有哪些？

## 1.1 理论基础——多模态涌现能力

讲到大语言模型的优势，一般首先要提到这类模型的涌现能力和思维链。这两者是大语言模型不断接近人类的关键特征。我们之所以认为 GPT-4 会是具有里程碑意义的一代，正是因为多模态的 GPT-4 会从视觉角度和视觉 - 文字语义融合方面涌现出更多的能力。2022-2023 年，我们可以认为 AI 是第一次睁开双眼理解这个世界。

在大型语言模型（LLM）中，涌现能力（Emergent Abilities）是指模型具有从原始训练数据中自动学习并发现新的、更高层次的特征和模式的能力。就中文释义而言，涌现能力也指大语言模型涌现出来的新能力。这有点类似于去超市遇到买二赠一，赠品的质量居然还出乎意料。

与大语言模型（LLM）相比，多模态大语言模型(Multi-modal Large Language Model，MLLM)可实现更好的常识推理性能，跨模态迁移更有利于知识获取，产生更多新的能力，加速了能力的涌现。这些独立模态或跨模态新特征、能力或模式通常不是通过目的明确的编程或训练获得的，而是模型在大量多模态数据中自然而然的学习到的。

![缩放定律（参数增加后精度损失连续减少）V.S. 涌现能力（1010-1011 参数后新能力的涌现）（来源：OpenAI）](https://assets.ng-tech.icu/item/20230404113147.png)

在语言模型发展的早期，通过在更多数据上训练更大的模型，可获得近似连续的精确度提升。(可称为缩放定律 /Scaling Laws)到了 2015 年左右，随着深度学习技术的发展和语料库的增大，模型达到一定的临界规模后，NLP 开发者们发现，大语言模型(包括 GPT-3、GLaM、LaMDA 和 Megatron-Turing NLG 等)开始表现出一些开发者最开始未能预测的、更复杂的能力和特性，这些新能力和新特性被认为是涌现能力的体现。

![当模型尺寸增加到一定大小后，新能力涌现](https://assets.ng-tech.icu/item/20230404121612.png)

我们在研究 GPT-4 时，发现 GPT-4 具备了 OpenAI 在预训练时和发表的技术报告中并未明确的能力。这些能力都属于涌现出来的能力。
