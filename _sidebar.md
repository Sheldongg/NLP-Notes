  - [1 0.导论](/0.导论/README.md)
    
  - [2 INTRODUCTION](/INTRODUCTION.md)
  - [3 LLM [1]](/LLM/README.md)
    - 3.1 GPT [1]
      - 3.1.1 ChatGPT [1]
        - 3.1.1.1 999.参考资料 [1]
          - [3.1.1.1.1 GPT 4 大模型硬核解读](/LLM/GPT/ChatGPT/999.参考资料/2023-GPT-4%20大模型硬核解读.md)
  - [4 Transformer [1]](/Transformer/README.md)
    - 4.1 999.参考资料 [4]
      - [4.1.1 NLP 中的 RNN、Seq2Seq 与 Attention 注意力机制](/Transformer/999.参考资料/2019-NLP%20中的%20RNN、Seq2Seq%20与%20Attention%20注意力机制.md)
      - [4.1.2 完全解析 RNN, Seq2Seq, Attention 注意力机制](/Transformer/999.参考资料/2020-完全解析%20RNN,%20Seq2Seq,%20Attention%20注意力机制.md)
      - [4.1.3 Transformer模型详解（图解最完整版）](/Transformer/999.参考资料/2021-Transformer模型详解（图解最完整版）.md)
      - [4.1.4 超详细图解 Self Attention](/Transformer/999.参考资料/2021-超详细图解%20Self-Attention.md)
  - [5 循环神经网络](/循环神经网络/README.md)
    
  - 6 经典自然语言 [4]
    - 6.1 主题模型 [1]
      - [6.1.1 LDA](/经典自然语言/主题模型/LDA.md)
    - 6.2 统计语言模型 [5]
      - [6.2.1 BERT [2]](/经典自然语言/统计语言模型/BERT/README.md)
        - [6.2.1.1 目标函数](/经典自然语言/统计语言模型/BERT/目标函数.md)
        - [6.2.1.2 输入表示](/经典自然语言/统计语言模型/BERT/输入表示.md)
      - [6.2.2 Word2Vec](/经典自然语言/统计语言模型/Word2Vec.md)
      - [6.2.3 基础文本处理](/经典自然语言/统计语言模型/基础文本处理.md)
      - [6.2.4 统计语言模型](/经典自然语言/统计语言模型/统计语言模型.md)
      - [6.2.5 词表示](/经典自然语言/统计语言模型/词表示.md)
    - 6.3 词嵌入 [2]
      - [6.3.1 概述](/经典自然语言/词嵌入/概述.md)
      - 6.3.2 词向量 [1]
        - [6.3.2.1 基于 Gensim 的 Word2Vec 实践](/经典自然语言/词嵌入/词向量/基于%20Gensim%20的%20Word2Vec%20实践.md)
    - 6.4 语法语义分析 [1]
      - [6.4.1 命名实体识别](/经典自然语言/语法语义分析/命名实体识别.md)
  - 7 行业应用 [2]
    - [7.1 机器人问答](/行业应用/机器人问答/README.md)
      
    - [7.2 聊天对话](/行业应用/聊天对话/README.md)
      