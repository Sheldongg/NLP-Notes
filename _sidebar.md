  - [1 00.导论](/00.导论/README.md)
    
  - 2 99.参考资料 [5]
    - [2.1 Numbers every LLM Developer should know](/99.参考资料/2023-Numbers%20every%20LLM%20Developer%20should%20know.md)
    - 2.2 吴恩达 《Building Systems with the ChatGPT API》 [3]
      - [2.2.1 1.Introduction](/99.参考资料/2023-吴恩达-《Building%20Systems%20with%20the%20ChatGPT%20API》/1.Introduction.md)
      - [2.2.2 11.conclusion](/99.参考资料/2023-吴恩达-《Building%20Systems%20with%20the%20ChatGPT%20API》/11.conclusion.md)
      - [2.2.3 readme](/99.参考资料/2023-吴恩达-《Building%20Systems%20with%20the%20ChatGPT%20API》/readme.md)
    - 2.3 吴恩达 《ChatGPT Prompt Engineering for Developers》 [2]
      - [2.3.1 00.README](/99.参考资料/2023-吴恩达-《ChatGPT%20Prompt%20Engineering%20for%20Developers》/00.README.md)
      - [2.3.2 01. 简介](/99.参考资料/2023-吴恩达-《ChatGPT%20Prompt%20Engineering%20for%20Developers》/01.%20简介.md)
      - [2.3.3 09. 总结](/99.参考资料/2023-吴恩达-《ChatGPT%20Prompt%20Engineering%20for%20Developers》/09.%20总结.md)
    - 2.4 吴恩达 《LangChain for LLM Application Development》 [3]
      - [2.4.1 1.开篇介绍](/99.参考资料/2023-吴恩达-《LangChain%20for%20LLM%20Application%20Development》/1.开篇介绍.md)
      - [2.4.2 8.课程总结](/99.参考资料/2023-吴恩达-《LangChain%20for%20LLM%20Application%20Development》/8.课程总结.md)
      - [2.4.3 readme](/99.参考资料/2023-吴恩达-《LangChain%20for%20LLM%20Application%20Development》/readme.md)
    - [2.5 陆奇 我的大模型世界观](/99.参考资料/2023-陆奇-我的大模型世界观.md)
  - [3 INTRODUCTION](/INTRODUCTION.md)
  - [4 LLM [5]](/LLM/README.md)
    - 4.1 99.参考资料 [1]
      - [4.1.1 cohere LLM University [1]](/LLM/99.参考资料/cohere-LLM%20University/README.md)
        - [4.1.1.1 01.What are Large Language Models? [1]](/LLM/99.参考资料/cohere-LLM%20University/01.What%20are%20Large%20Language%20Models?/README.md)
          - [4.1.1.1.1 01.Text Embeddings](/LLM/99.参考资料/cohere-LLM%20University/01.What%20are%20Large%20Language%20Models?/01.Text%20Embeddings.md)
    - 4.2 GPT [1]
      - 4.2.1 ChatGPT [1]
        - 4.2.1.1 99.参考资料 [1]
          - [4.2.1.1.1 GPT 4 大模型硬核解读](/LLM/GPT/ChatGPT/99.参考资料/2023-GPT-4%20大模型硬核解读.md)
    - 4.3 LangChain [1]
      - [4.3.1 LangChain 中文入门教程](/LLM/LangChain/2023-LangChain%20中文入门教程.md)
    - 4.4 代码生成 [1]
      - 4.4.1 99.参考资料 [1]
        - [4.4.1.1 An example of LLM prompting for programming](/LLM/代码生成/99.参考资料/2023-An%20example%20of%20LLM%20prompting%20for%20programming.md)
    - 4.5 大模型微调 [1]
      - 4.5.1 99.参考资料 [1]
        - [4.5.1.1 Finetuning Large Language Models](/LLM/大模型微调/99.参考资料/2023-Finetuning%20Large%20Language%20Models.md)
  - [5 Transformer [1]](/Transformer/README.md)
    - 5.1 99.参考资料 [5]
      - [5.1.1 NLP 中的 RNN、Seq2Seq 与 Attention 注意力机制](/Transformer/99.参考资料/2019-NLP%20中的%20RNN、Seq2Seq%20与%20Attention%20注意力机制.md)
      - [5.1.2 完全解析 RNN, Seq2Seq, Attention 注意力机制](/Transformer/99.参考资料/2020-完全解析%20RNN,%20Seq2Seq,%20Attention%20注意力机制.md)
      - [5.1.3 Transformer模型详解（图解最完整版）](/Transformer/99.参考资料/2021-Transformer模型详解（图解最完整版）.md)
      - [5.1.4 超详细图解 Self Attention](/Transformer/99.参考资料/2021-超详细图解%20Self-Attention.md)
      - [5.1.5 Transformers from Scratch](/Transformer/99.参考资料/2023-Transformers%20from%20Scratch.md)
  - [6 循环神经网络](/循环神经网络/README.md)
    
  - 7 经典自然语言 [4]
    - 7.1 主题模型 [1]
      - [7.1.1 LDA](/经典自然语言/主题模型/LDA.md)
    - 7.2 统计语言模型 [5]
      - [7.2.1 BERT [2]](/经典自然语言/统计语言模型/BERT/README.md)
        - [7.2.1.1 目标函数](/经典自然语言/统计语言模型/BERT/目标函数.md)
        - [7.2.1.2 输入表示](/经典自然语言/统计语言模型/BERT/输入表示.md)
      - [7.2.2 Word2Vec](/经典自然语言/统计语言模型/Word2Vec.md)
      - [7.2.3 基础文本处理](/经典自然语言/统计语言模型/基础文本处理.md)
      - [7.2.4 统计语言模型](/经典自然语言/统计语言模型/统计语言模型.md)
      - [7.2.5 词表示](/经典自然语言/统计语言模型/词表示.md)
    - 7.3 词嵌入 [2]
      - [7.3.1 概述](/经典自然语言/词嵌入/概述.md)
      - 7.3.2 词向量 [1]
        - [7.3.2.1 基于 Gensim 的 Word2Vec 实践](/经典自然语言/词嵌入/词向量/基于%20Gensim%20的%20Word2Vec%20实践.md)
    - 7.4 语法语义分析 [1]
      - [7.4.1 命名实体识别](/经典自然语言/语法语义分析/命名实体识别.md)
  - 8 行业应用 [2]
    - [8.1 机器人问答](/行业应用/机器人问答/README.md)
      
    - [8.2 聊天对话](/行业应用/聊天对话/README.md)
      